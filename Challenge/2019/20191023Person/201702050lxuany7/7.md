# 第七次课时总结
## 计算机视觉检测
  计算机视觉
   近几年来，目标检测算法取得了很大的突破。比较流行的算法可以分为两类，一类是基于Region Proposal的R-CNN系算法（R-CNN，Fast R-CNN, Faster R-CNN），它们是two-stage的，需要先使用启发式方法（selective search）或者CNN网络（RPN）产生Region Proposal，然后再在Region Proposal上做分类与回归。而另一类是Yolo，SSD这类one-stage算法，其仅仅使用一个CNN网络直接预测不同目标的类别与位置。第一类方法是准确度高一些，但是速度慢，但是第二类算法是速度快，但是准确性要低一些。这可以在图2中看到。本文介绍的是Yolo算法，其全称是You Only Look Once: Unified, Real-Time Object Detection，其实个人觉得这个题目取得非常好，基本上把Yolo算法的特点概括全了：You Only Look Once说的是只需要一次CNN运算，Unified指的是这是一个统一的框架，提供end-to-end的预测，而Real-Time体现是Yolo算法速度快。这里我们谈的是Yolo-v1版本算法，其性能是差于后来的SSD算法的，但是Yolo后来也继续进行改进，产生了Yolo9000算法。本文主要讲述Yolo-v1算法的原理，特别是算法的训练与预测中详细细节，最后将给出如何使用TensorFlow实现Yolo算法。
## Yolo介绍
  YOLO（You Only Look Once）是一种基于深度神经网络的对象识别和定位算法，其最大的特点是运行速度很快，可以用于实时系统.人类视觉系统快速且精准，只需瞄一眼（You Only Look Once）即可识别图像中物品及其位置。作者用了You Only Look Once的首字母YOLO来表示其算法，相当有趣。YOLO为一种新的目标检测方法，该方法的特点是实现快速检测的同时还达到较高的准确率。作者将目标检测任务看作目标区域预测和类别预测的回归问题。该方法采用单个神经网络直接预测物品边界和类别概率，实现端到端（end to end）的物品检测。同时，该方法检测速非常快，基础版可以达到45帧/s的实时检测；FastYOLO可以达到155帧/s。与当前最好系统相比，YOLO目标区域定位误差更大，但是背景预测的准确性优于当前最好的方法。

    YOLO的网络结构：模型采用卷积神经网络结构。开始的卷积层提取图像特征，全连接层预测输出概率。模型结构类似于GoogleNet，如图3所示。作者还训练了YOLO的快速版本（fast YOLO）。Fast YOLO模型卷积层和filter更少。最终输出为7×7×30的tensor。
## 设计理念
  整体来看，Yolo算法采用一个单独的CNN模型实现end-to-end的目标检测，整个系统如图5所示：首先将输入图片resize到448x448，然后送入CNN网络，最后处理网络预测结果得到检测的目标。相比R-CNN算法，其是一个统一的框架，其速度更快，而且Yolo的训练过程也是end-to-end的。
![](media\1.png)
## 运行环境
    运行环境：Windows+显卡MX150+python3.6.5+tensorflow1.8
## 运行效果如下：
检测了我和路飞
![](media\2.jpg)
![](media\2.png)
## 总结
  YOLO算法是一种基于深度神经网络的对象识别和定位算法。根据本课时的学习，我对YOLO的浅显理解如下：Yolo将一张图片分为若干个小格，然后和分别进行识别每一个小格并给出每一个小格的输出结果，每一个小格都会对系统输出不同的结果，最终yolo讲每个小格给出的输出结果进行汇总然后总输出识别结果。YOLO不同于其它一些目标检测算法，它是将目标检测抽象为一个回归问题，直接使用一个神经网络，输入为原始图片，输出为边界框坐标、目标类别、目标置信度等，YOLO将其他模型分开的部分都综合到一个神经网络中，使得训练能够采用端到端（end-to-end）来优化。在本次实验中发现Yolo的识别定位不是很准确，检测的类别也较少，但是它作为我们入门阶段依然是一个非常优秀的算法。总的来说这次实验比较成功，我逐步理解了研究视觉检测的复杂问题，相信今天的知识会广泛的用到以后的学习中去。