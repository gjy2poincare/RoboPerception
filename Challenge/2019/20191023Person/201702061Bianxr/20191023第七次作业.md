###   20191022 第七次作业
姓名：bxr   
学号：201702061

#####< 车载信息处理课程学习———ONNX模型推理环境感知>
   
     本节课的主要目的首先是了解yolo网站的作用和性能，然后通过老师
     给的代码用ONNX模型实现环境感知，理解环境感知。本节课的内容很
     有意思也很有意义，以下是我的心得体会和课程概述。
     
#### 一 环境感知

首先，我们要知道环境感知是什么。
环境感知是现代智能驾驶汽车最重要的技术。  人类驾驶员会根据行人的移动轨迹大概评估其下一步的位置，然后根据车速，计算出安全空间（路径规划），公交司机最擅长此道。无人驾驶汽车同样要能做到。要注意这是多个移动物体的轨迹的追踪与预测，难度比单一物体要高得多。这就是环境感知，也是无人驾驶汽车最具难度的技术。
自动驾驶的四大核心技术，分别是环境感知，精确定位，路径规划，线控执行。还记得在大一的时候，龚老师曾带我们去第二实验楼看过学长们的实验，他们当时就是运用环境感知，将周围的物体识别出来。环境感知是其中研究最多的部分，不过基于视觉的环境感知是无法满足无人汽车自动驾驶要求的。实际的无人驾驶汽车面对的路况远比实验室仿真或者试车场的情况要复杂得多，这就需要建立大量的数学方程。而良好的规划必须建立对周边环境，尤其是动态环境的深刻理解。
环境感知包括三个方面，路面，静态物体，动态物体。对于动态物体，不仅要检测还要对其轨迹进行追踪，并根据追踪结果，预测该物体下一步的轨迹。这就是无人驾驶汽车中最难的部分。
了解了这些后，我发现我们做的实验真的是很基础的部分，要做的事情和要学习的地方还有很多。

#### 二 YOLO

YOLO的检测思想将目标检测作为回归任务来解决。YOLO 的核心思想就是利用整张图作为网络的输入，直接在输出层回归 bounding box（边界框） 的位置及其所属的类别。
YOLO 的实现方法，是将一幅图像分成 SxS 个网格（grid cell），如果某个 object 的中心落在这个网格中，则这个网格就负责预测这个 object。 由于输出层为全连接层，因此在检测时，YOLO 训练模型只支持与训练图像相同的输入分辨率。
为了更好的解释，这里附上我找到的一张图：

![](picture\065.jpg)

YOLO 方法模型训练依赖于物体识别标注数据，因此，对于非常规的物体形状或比例，YOLO 的检测效果并不理想。

YOLO 采用了多个下采样层，网络学到的物体特征并不精细，因此也会影响检测效果。

YOLO 的损失函数中，大物体 IOU 误差和小物体 IOU 误差对网络训练中 loss 贡献值接近（虽然采用求平方根方式，但没有根本解决问题）。因此，对于小物体，小的 IOU 误差也会对网络优化过程造成很大的影响，从而降低了物体检测的定位准确性。

YOLO 的缺点：
YOLO 对相互靠的很近的物体，还有很小的群体检测效果不好，这是因为一个网格中只预测了两个框，并且只属于一类。

同一类物体出现的新的不常见的长宽比和其他情况时，泛化能力偏弱。

由于损失函数的问题，定位误差是影响检测效果的主要原因。尤其是大小物体的处理上，还有待加强。

YOLO 代表着目前最先进物体检测的水平，在多种监测数据集中都要快过其他检测系统，并可以在速度与精确度上进行权衡。
YOLO 9000 的网络结构允许实时地检测超过9000种物体分类，这归功于它能同时优化检测与分类功能。使用 WordTree 来混合来自不同的资源的训练数据，并使用联合优化技术同时在 ImageNet 和 COCO 数据集上进行训练，YOLO9000 进一步缩小了监测数据集与识别数据集之间的大小代沟。

#### 三 实践
实验成果：

![](picture\061.jpg)

![](picture\062.jpg)
重要代码：
![](picture\063.jpg)

最终结果：

![](picture\064.jpg)


#### 四 实验心得
      本节课首先我通过浏览yolo网站，了解了这个强大的物体检测技术以及他的数学用法。然后用老师发的代码做出了基于ONNX模型推理的环境感知，检测出了人脸，杯子，牛奶，手机等物品。最后理解了里面重要代码含义。这节课很有意思，感觉和之前自己了解的和看到的联系了起来，智能汽车的实现远比我想象中要难得多，要依赖多方面的知识的综合。通过本节课的学习，使我对环境感知有了更加深刻的理解，也对智能汽车这一系统有了更加清楚地认识。
