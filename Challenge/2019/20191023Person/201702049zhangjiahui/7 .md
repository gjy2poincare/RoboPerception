# 第七次作业
## *一.YOLO-v1.2-WinML-Sample*
YOLO是一个最先进的实时物体检测系统。在Pascal Titan X上，它以每秒30帧的速度处理图像，在Coco Test-Dev上有57.9%的地图。与其他探测器的比较，Yolo v3非常快速和准确。在0.5 IOU处测得的MAP中，Yolo v3与焦距损失相当，但速度快了约4倍。此外，可以轻松地权衡速度和准确性之间的简单改变模型的大小。

YOLO之前的物体检测系统使用分类器来完成物体检测任务。为了检测一个物体，这些物体检测系统要在一张测试图的不同位置和不同尺寸的bounding box上使用该物体的分类器去评估是否有该物体。如DPM系统，要使用一个滑窗（sliding window）在整张图像上均匀滑动，用分类器评估是否有物体。

在DPM之后提出的其他方法，如R-CNN方法使用region proposal来生成整张图像中可能包含待检测物体的potential bounding boxes，然后用分类器来评估这些boxes，接着通过post-processing来改善bounding boxes，消除重复的检测目标，并基于整个场景中的其他物体重新对boxes进行打分。整个流程执行下来很慢，而且因为这些环节都是分开训练的，检测性能很难进行优化。
### *How It Works*
先前的检测系统重新利用分类器或定位器来执行检测。他们将模型应用于多个位置和比例的图像。图像的高分区域被认为是检测。使用完全不同的方法，将单一的神经网络应用于完整的图像。该网络将图像分为多个区域，并预测每个区域的包围盒和概率。这些边界框由预测的概率加权。

与基于分类器的系统相比，其模型有几个优点。它在测试时查看整个图像，因此它的预测由图像中的全局上下文通知。它也用单一的网络评估来预测，不像r-cnn这样的系统需要数千张单一的图像。这使得它非常快，比r-cnn快1000倍，比r-cnn快100倍。YOLO v3使用了一些技巧来改进训练和提高性能，包括：多尺度预测、更好的主干分类器等等。
## *二.Ackonwledgements*
### * 用于目标检测的yolov2简介
YOLO模型是一个用于目标检测的实时神经网络，可检测20个不同的类。它由9个卷积层和6个最大池层组成，是更复杂的全yolov2网络的较小版本。现在可以在windows 10中使用onnx模型。我们必须做的第一件事是将模型转换为onnx格式。我们可以使用onnx工具，或从azure人工智能库下载已转换的模型
### * 创建一个基本的windows 10app并在canera中使用yolov2进行对象检测
现在已经下载了yolov2 onnx文件。我们可以创建一个uwp应用程序来使用该模型。步骤如下：
1. 创建了一个新的windows 10 uwp应用程序。这个名称是super original。
![](01.png)
2. 使用相机作为用yolov2处理的图像源。有很多这样做的例子。在本例中，我们将使用WindowsCommunityToolkitV3.0的控件。通过nuget添加以下包
    * Microsoft.Toolkit.uwp.ui软件包
    * Microsoft.Toolkit.uwp.ui.控件
![](02.png)
1. 在xaml中添加了一个控制camerapreview
![](03.png)
4. 启用了使用应用程序清单中的相机所需的权限。应用程序有一个功能强大的摄像头
5. 现在是开始使用yolov2的时候了。最新版本的visual studio 2017允许我们将onnx模型导入到项目中，ide将创建使用它所需的类。我们将现有的文件添加到文件[TYY-YOLVO2 ]。onnx]。
![](05.png)
1. 现在可以看到生成的类，在其中可以找到3个类
    * 模型的输入类
    * 模型的输出类
    * 与模型一起工作的类
  
将模型加载到应用程序中了。在初始化相机之前执行此操作
    ![](06.png)

7. 因为将使用模型作为应用程序的一部分，所以必须定义它在构建过程中被视为一个内容

    ![](07.png)
8. 下一步是使用yolov2模型计算相机的帧。这里的代码展示了如何使用导入模型时创建的类。
9.  断点是一种显示模型输出和模型输出信息的有用方法。
![](09.png)
### * 调整yolov2输出的大小以支持多种格式并每秒处理和显示帧
已用tiny-yolov2编码了一个实时视频摄录过程。模型返回的结果是416×416大小的图像，这就是为什么检测到的人的帧看起来有点奇怪。

使用输出并不复杂，因此它可以适应网络摄像头控件的大小，只有几行代码。这样就可以用正确的格式画出框架。在下面的图像中，可以看到一个人是如何被检测到的，精度很低，而且墙上的一张图片也可以被检测为监视器。

仅当应用程序调整大小时才获取网络摄像头控件的值。
添加了一个可视指示器作为状态栏，它显示每秒处理的帧数和应用程序中元素的实际大小。
## *三.Setup*
要试用预发布的WindowsML，您需要Windows10Insider预览版（内部版本17728或更高版本）和Windows10SDK（内部版本17723或更高版本）。

如果在桌面Windows上运行，则需要将配置设置为x64。
## *四.Model*
### ONNXMLTools
* 介绍
onnxmltools允许您不同机器学习工具包中的模型转换为onnx。目前支持以下工具包：

    Keras (a wrapper of keras2onnx converter)
    Tensorflow (a wrapper of tf2onnx converter)
    scikit-learn (a wrapper of skl2onnx converter)
    Apple Core ML
    Spark ML (experimental)
    LightGBM
    libsvm
    XGBoost

* 安装
可以从pypi安装最新版本的onnxmltools：

pip install onnxmltools

或从源安装：

pip install git+https://github.com/onnx/onnxmltools

如果选择从源代码安装onnxmltools，则必须在安装onnx包之前设置环境变量onnx_ml=1。
* 依赖关系
这个包依赖于nx、numpy和protobuf。如果要从scikit learn、core ml、keras、lightgbm、sparkml、xgboost或libsvm转换模型，则需要一个环境，并从下面的列表中安装相应的包：

    scikit-learn
    CoreMLTools
    Keras (version 2.0.8 or higher) with the corresponding Tensorflow version
    LightGBM (scikit-learn interface)
    SparkML
    XGBoost (scikit-learn interface)
    libsvm

onnxmltools已经用python 2.7、3.5、3.6和3.7进行了测试。Note: some wrapped converters may not support python 2.x anymore. 
* 实例
如果希望转换后的onnx模型与某个onnx版本兼容，在调用转换函数时指定target_opset参数。下面的Keras模型转换示例演示了这一点。可以在版本控制文档中标识从onnx操作集（称为操作集）到onnx版本的映射。
* Keras到Onnx的转换,其中target_opset=7对应于onnx版本1.2。
* coreml到onnx的转换,用于将核心ml模型转换为onnx模型。
* 测试模型转换器
onnxmltools将模型转换为onnx格式，然后可以使用onnx格式计算选择的后端的预测。
## *五.总结*
通过查询资料了解YOLO算法的优缺点：YOLO的速度非常快；YOLO是基于图像的全局信息进行预测的；YOLO可以学到物体的generalizable representations；准确率高。位置精确性差，对于小目标物体以及物体比较密集的也检测不好；YOLO虽然可以降低将背景检测为物体的概率，但同时导致召回率较低。YOLO算法中把目标检测（object detection）问题处理成回归问题，用一个卷积神经网络结构就可以从输入图像直接预测bounding box和类别概率。