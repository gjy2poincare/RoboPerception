# Step8学习笔记

## 软件安装
输入命令
pip install opencv-python
更新pip
easy_install --upgrade pip
找到python文件夹中的cv2
将cv2文件夹导入到CH17的目录下即可
## 卷积神经网络原理

### 卷积神经网络的典型结构
* 卷积层
* 激活函数层
* 池化层
* 全连接分类层

### 卷积核
一个小矩阵
作用：抓取重要特征，除去非重要特征。
![avatar](https://note.youdao.com/yws/api/personal/file/B0EF090798DD4230A752287A1876D1D3?method=download&shareKey=3941bafeb3c83e0c37df69339ecdd2d3)

### 卷积神经网络的学习
在最后一层的池化后面，把所有特征数据变成一个一维的全连接层，然后就和普通的深度全连接网络一样了，通过在最后一层的softmax分类函数，以及多分类交叉熵函数，对比图片的OneHot编码标签，回传误差值，从全连接层传回到池化层，通过激活函数层再回传给卷积层，对卷积核的数值进行梯度更新，实现卷积核数值的自我学习。

## 卷积的前向计算
需要理解的概念：
卷积的计算过程，单人单出，单入多出，多入单出，以及多入多出。步长stride，以及填充padding。

### 结合慕课笔记进行阐释
卷积
离散求和，连续求积分
卷积实际上是滤波器
g函数能够抓取f的重要特征，隐去非重要特征。
特征能够保留，且变少了。
用较小卷积核，深度变深，可以把特征获取更全。
![avatar](https://note.youdao.com/yws/api/personal/file/E364687477EF428CB84E7B574A26B5E3?method=download&shareKey=beb9d82917a8a35cbe8d71b738dc64cb)

图实际上是一个函数，每个像素对应一个位置，x表示位置，y表示编码。
图形编码中g函数为核函数
图形编码观察二维信号卷积过程

感受野是CNN中的某一层输出结果的一个元素对应输入层的一个映射，即feature map上的一个点所对应的输入图上的区域。
![avatar](https://note.youdao.com/yws/api/personal/file/8F07F68566AE48D49D3F7621C1BE20AB?method=download&shareKey=719d258b3a8b60578e455d167d4311e1)
右上图卷积层矩阵输出大小公式中：
s表示步长，以一个像素为单位。
p表示在编码的外围补0的圈数
f表示卷积核的大小
![avatar](https://note.youdao.com/yws/api/personal/file/1E7ED17BCB9B45618101B71B37235727?method=download&shareKey=9896b18335affdf442d1629bb71280ef)
公式含义：以图中黑框为例
（7+2*0-3）/ 1+1=5 （s=1），若s=2，则Nout=3，即图中所示3*3的结果。

可以通过不同的卷积核得到同一个图的不同特征：
多个卷积核即多个通道对特征图进行卷积
![avatar](https://note.youdao.com/yws/api/personal/file/2A5DCAB10DD744D7AA62F8E2380EB4B7?method=download&shareKey=bf8cc5566d09472885a89bb077d6926b)

彩色图中RGB原理（三基色原理）：任何一种都可以按照红蓝绿三种颜色调和而成。
即彩色图中任意像素可分解成三个矩阵。（分解成RGB三个通道）

多通道卷积
三个通道分别用不同的卷积核卷积，再将相同位置的值相加。
![avatar](https://note.youdao.com/yws/api/personal/file/1744AC2F769E4CAF8CDD2A030C9A1FDD?method=download&shareKey=29758d73914282d5be038bb24e072362)

池化：下采样
平均池化：Mean Pooling 进一步把编码压缩
最大池化：Max Pooling 求最突出特征
![avatar](https://note.youdao.com/yws/api/personal/file/B1EC48D4EEB4451D99585B80ED48F8FE?method=download&shareKey=361a8ff90f934e616be4d051b61338f4)

如果矩阵不对称，则水平和垂直分别计算
p = （f-1）/ 2

Lenet框架：
两对卷积池化层，两个全连接层。
共享权重：压缩成一个像素的过程中，权重相同，含义：对于同一个通道中，（相同指输入输出都相同，若输出有六个，则有六组权重参数）权重相同。
![avatar](https://note.youdao.com/yws/api/personal/file/BEFA05031BF740A69D80A2F6A207002D?method=download&shareKey=c92e5df44f3373e10fdf3108a9a45cf3)
相比于传统神经网络中每个连接数目在训练中的权重都得改变，卷积神经网络因为有权重共享，即参数数目为要训练的权重总数，训练量减少。
![avatar](https://note.youdao.com/yws/api/personal/file/727D1EB5550D44758DE4D9E3AE4C66E8?method=download&shareKey=eaa0bc11c3603eeaeb798413b0e5e179)

参数数目中：2为1+1（2*2的池化核共用一个权重，共用一个偏置）此处与卷积核不同。

如右上图所示：6个变16个过程中一个卷积核对多个特征图分别作卷积再把结果累加。
物理含义：更多的通道可以获得更多的特征，通过融合获得更丰富的特征。
一个卷积核对不同输入通道的权重不同，相同通道中权重相同，每个输入通道对应一个偏置。
![avatar](https://note.youdao.com/yws/api/personal/file/8D8E8CC592AF43F9970A90FDDA54ED96?method=download&shareKey=a966a525f2a9a81ea43f7daee8dc9a7c)

第二对卷积和池化之间，方法和前面相同，池化核中2*2的权重只记一个
![avatar](https://note.youdao.com/yws/api/personal/file/999615C5DCAC4C3D8C85C76CFA08F8C5?method=download&shareKey=0aaa73252a932a80e089b08d8c8512d5)

总结：所谓共享权重，在卷积变化中，指的是一个卷积核的大小，而在池化中指的是2*2池化核始终相同为1。

到此完成了特征获取。深度学习的特征获取通过卷积池化，传统的神经网络通过人工BP算法获取。

通过全连接层Dense函数完成分类。两层映射更充分。
最后的输出层作类别映射。softmax函数

全连接层：作拟合映射工作

把编码转换成向量。Flatten函数

## 卷积核的实现

```Python
class ConvWeightsBias(WeightsBias_2_1):
    def __init__(self, output_c, input_c, filter_h, filter_w, init_method, optimizer_name, eta):
        self.FilterCount = output_c
        self.KernalCount = input_c
        self.KernalHeight = filter_h
        self.KernalWidth = filter_w
        ...

    def Initialize(self, folder, name, create_new):
        self.WBShape = (self.FilterCount, self.KernalCount, self.KernalHeight, self.KernalWidth)        
        ...
```
![avatar](https://note.youdao.com/yws/api/personal/file/0D085B06B37C4CF0B1F77A8E6EC5CEDA?method=download&shareKey=c5a8eb87dc0daf8ba326c98bb7d83fce)
- FilterCount=2，第一维，过滤器数量，对应输出通道数。
- KernalCount=3，第二维，卷积核数量，对应输入通道数。两个Filter里面的Kernal数必须相同。
- KernalHeight=5，KernalWidth=5，卷积核的尺寸，第三维和第四维。同一组WeightsBias里的卷积核尺寸必须相同。

代码测试
![avatar](https://note.youdao.com/yws/api/personal/file/C3158AD6804C43F8B8F840D367FC7EFA?method=download&shareKey=a9f5b0da43b13ef1374eead554392773)
![avatar](https://note.youdao.com/yws/api/personal/file/D1B295A7B7B5491CBA806F7E4BB7AAB4?method=download&shareKey=092293756e1b989014352a2ffa7767b9)
* `test_2d_conv`，理解2维下`im2col`的工作原理
* `understand_4d_im2col`，理解4维下`im2col`的工作原理
* `test_4d_im2col`，比较两种方法的结果，从而验证正确性
* `test_performance`，比较两种方法的性能

### 卷积反向传播
```Python
    def backward_numba(self, delta_in, flag):
        # 如果正向计算中的stride不是1，转换成是1的等价误差数组
        dz_stride_1 = expand_delta_map(delta_in, ...)
        # 计算本层的权重矩阵的梯度
        self._calculate_weightsbias_grad(dz_stride_1)
        # 由于输出误差矩阵的尺寸必须与本层的输入数据的尺寸一致，所以必须根据卷积核的尺寸，调整本层的输入误差矩阵的尺寸
        (pad_h, pad_w) = calculate_padding_size(...)
        dz_padded = np.pad(dz_stride_1, ...)
        # 计算本层输出到下一层的误差矩阵
        delta_out = self._calculate_delta_out(dz_padded, flag)
        #return delta_out
        return delta_out, self.WB.dW, self.WB.dB

    # 用输入数据乘以回传入的误差矩阵,得到卷积核的梯度矩阵
    def _calculate_weightsbias_grad(self, dz):
        self.WB.ClearGrads()
        # 先把输入矩阵扩大，周边加0
        (pad_h, pad_w) = calculate_padding_size(...)
        input_padded = np.pad(self.x, ...)
        # 输入矩阵与误差矩阵卷积得到权重梯度矩阵
        (self.WB.dW, self.WB.dB) = calcalate_weights_grad(...)
        self.WB.MeanGrads(self.batch_size)

    # 用输入误差矩阵乘以（旋转180度后的）卷积核
    def _calculate_delta_out(self, dz, layer_idx):
        if layer_idx == 0:
            return None
        # 旋转卷积核180度
        rot_weights = self.WB.Rotate180()
        # 定义输出矩阵形状
        delta_out = np.zeros(self.x.shape)
        # 输入梯度矩阵卷积旋转后的卷积核，得到输出梯度矩阵
        delta_out = calculate_delta_out(dz, ..., delta_out)

        return delta_out
```
![avatar](https://note.youdao.com/yws/api/personal/file/7AE199E9EBDD40F4831C08AEC59D90B9?method=download&shareKey=7aeb653d0fc2f0106dd74c2f98e5368a)
![avatar](https://note.youdao.com/yws/api/personal/file/0A32D4E5DF214077BB097DE44E9BDFD3?method=download&shareKey=9cb9acbbd4608c09cf10c9194cd7a196)

### 实现颜色分类
1x1卷积
这样做可以达到两个目的：

1. 跨通道信息整合
2. 降维以减少学习参数

1x1的卷积核关注的是不同通道的相同位置的像素之间的相关性，而不是同一通道内的像素的相关性，在本例中，意味着它关心的彩色通道信息，通过不同的卷积核，把彩色通道信息转变成另外一种表达方式，在保留原始信息的同时，还实现了降维。

![avatar](https://note.youdao.com/yws/api/personal/file/80E0E035C9404A29A7501738B3FC388C?method=download&shareKey=b563432d9b594da560e62449b494a191)
![avatar](https://note.youdao.com/yws/api/personal/file/361DEAF808AB4DDF9FE6EE195129F316?method=download&shareKey=3397d4ef262661a59b13edd7229fc950)

用2352(=784x3)的矢量做为样本特征值，送入DNN进行训练。
出现以下报错：
![avatar](https://note.youdao.com/yws/api/personal/file/9AA310D67A2842D1B5D4F25061A14BB5?method=download&shareKey=67bdd764ab624e629bab7098f282fb94)


将CNN中1x1的卷积核从2个改为4个
![avatar](https://note.youdao.com/yws/api/personal/file/A62C782B5A734C04BC333DAE73921BCA?method=download&shareKey=1f65318f8d7e7f900af0e0ef6a5aaa91)

### 实现几何图形分类
分别跑出CNN核DNN的代码
![avatar](https://note.youdao.com/yws/api/personal/file/2A3F0D7940254D9CBDD6F535145FCA33?method=download&shareKey=c7db95e36e00d83bf4aaef4dded8a576)
![avatar](https://note.youdao.com/yws/api/personal/file/A62C782B5A734C04BC333DAE73921BCA?method=download&shareKey=1f65318f8d7e7f900af0e0ef6a5aaa91)

DNN
![avatar](https://note.youdao.com/yws/api/personal/file/5163628BC0E8496E89C84B3CA532145C?method=download&shareKey=49ea144eca0c71140760b82e469192a0)
![avatar](https://note.youdao.com/yws/api/personal/file/5B4ACD8DDE724C50A48296C8FA6FC820?method=download&shareKey=d30ae527750f0d85687d74292ec21c10)

### 实现集合图形和图像分类
在CNN中将3x3的卷积核改成5x5，观察实验结果
![avatar](https://note.youdao.com/yws/api/personal/file/FC015365CE36418A8CF0C3A325220FE6?method=download&shareKey=46aab861fa941ee5bd3fec60d736cf8d)
![avatar](https://note.youdao.com/yws/api/personal/file/79D7342AE95D4349B5EAD9E534D37322?method=download&shareKey=c965d7d7228fd8dd4e03a8c5c3cafc50)

## 学习总结和心得体会
在测试图形形状时，DNN的速度明显快于CNN。从修改代码可看出，当增加卷积核数量时，精确度能够得到提升，但是代码跑的时间也会增长。CNN在图像识别的精确度普遍比DNN要高。当将卷积核变大，不能有效的提高精确度，其原因个人分析在于卷积核越小能够有利于提取出更显著的特征。通过本次学习，结合原来的知识，重新整体温故了卷积神经网络的结构和内部的各个层，通过修改跑代码，也对一些概念有了更加深刻的体会。