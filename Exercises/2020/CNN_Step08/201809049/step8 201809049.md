# Step8-CNN

## 卷积神经网路

### 概述

#### 简介
卷积神经网络（CNN，Convolutional Neural Net)是神经网络的类型之一，在图像识别和分类领域中取得了非常好的效果，比如识别人脸、物体、交通标识等，这就为机器人、自动驾驶等应用提供了坚实的技术基础。

#### 结构
一个典型的卷积神经网络的结构如图所示。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/17/conv_net.png" />

一个典型的卷积神经网络中，会至少包含以下几个层：

- 输入层
- 卷积层
- 池化层
- Inception模块
- 全连接层
- 输出层

#### 作用
代码运行效果：
![avatar](\picture\ch17-0.png)

9个卷积核的作用：

|序号|名称|说明|
|---|---|---|
|1|锐化|如果一个像素点比周围像素点亮，则此算子会令其更亮|
|2|检测竖边|检测出了十字线中的竖线，由于是左侧和右侧分别检查一次，所以得到两条颜色不一样的竖线|
|3|周边|把周边增强，把同色的区域变弱，形成大色块|
|4|Sobel-Y|纵向亮度差分可以检测出横边，与横边检测不同的是，它可以使得两条横线具有相同的颜色，具有分割线的效果|
|5|Identity|中心为1四周为0的过滤器，卷积后与原图相同|
|6|横边检测|检测出了十字线中的横线，由于是上侧和下侧分别检查一次，所以得到两条颜色不一样的横线|
|7|模糊|通过把周围的点做平均值计算而“杀富济贫”造成模糊效果|
|8|Sobel-X|横向亮度差分可以检测出竖边，与竖边检测不同的是，它可以使得两条竖线具有相同的颜色，具有分割线的效果|
|9|浮雕|形成大理石浮雕般的效果|

#### 后续运算
效果：
![avatar](\picture\ch17-1.png)

四个子图，依次展示了：

1. 原图，用cv2读取出来的图片，其顺序是反向的；
2. 卷积结果，使用了3x3的卷积核，用的是sobel x算子；
3. 激活结果，一层Relu激活计算，把小于0的值都去掉了，只留下了一些边的特征；
4. 池化结果，是图三的四分之一大小，虽然图片缩小了，但是特征都没有丢失，反而因为图像尺寸变小而变得密集，亮点的密度要比图三大而粗。

#### 性质
对于人类的视觉系统来说都可以轻松应对，即平移不变性、旋转视角不变性、尺度不变性。

1. 连接性
2. 表征学习
3. 生物学相似性

### 卷积的向前计算

#### 定义
1. 连续定义：两函数的傅里叶变换的乘积等于它们卷积后的傅里叶变换。
2. 离散定义：
   $$h(x) = (f*g)(x) = \sum^{\infty}_{t=-\infty} f(t)g(x-t) \tag{2}$$

#### 实例
结论：

1. 我们实现的卷积操作不是原始数学含义的卷积，而是工程上的卷积，可以简称为卷积
2. 在实现卷积操作时，并不会反转卷积核

#### 编程模型
侧重于五个概念的关系：

- 输入 Input Channel
- 卷积核组 WeightsBias
- 过滤器 Filter
- 卷积核 kernal
- 输出 Feature Map

#### 步长 stride

例子中，每次计算后，卷积核会向右或者向下移动一个单元，即步长stride = 1。

#### 填充 padding

如果原始图为4x4，用3x3的卷积核进行卷积后，目标图片变成了2x2。若想保持目标图片和原始图片为同样大小，一般我们会向原始图片周围填充一圈0，然后再做卷积。

#### 注意
1. 一般情况下，我们用正方形的卷积核，且为奇数
2. 如果计算出的输出图片尺寸为小数，则取整，不做四舍五入

### 前向计算代码实现

结果：
![avatar](\picture\ch17-2.1.png)
![avatar](\picture\ch17-2.2.png)

### 卷积层的训练
同全连接层一样，卷积层的训练也需要从上一层回传的误差矩阵，然后计算：

1. 本层的权重矩阵的误差项
2. 本层的需要回传到下一层的误差矩阵

#### 计算反向传播的梯度矩阵

正向公式：

$$Z = W*A+b \tag{0}$$

其中，W是卷积核，*表示卷积（互相关）计算，A为当前层的输入项，b是偏移（未在图中画出），Z为当前层的输出项，但尚未经过激活函数处理。

#### 多个卷积核时
有多个卷积核也就意味着有多个输出通道。

#### 多个输入时
当输入层是多个图层时，每个图层必须对应一个卷积核。

#### 实例
效果：
![avatar](\picture\ch17-3.png)

左侧为原始图片（80x80的灰度图），右侧为经过3x3的卷积后的结果图片（78x78的灰度图）。由于算子是横边检测，所以只保留了原始图片中的横边。

#### 结果
真实值和训练值的卷积结果区别人眼是看不出什么差异来的。
由此我们可以直观地理解到卷积核的训练过程并不复杂。

### 反向传播代码实现

结果：
![avatar](\picture\ch17-4.png)

### 池化层

#### 常用方法

池化 pooling，又称为下采样，downstream sampling or sub-sampling。

池化方法分为两种，一种是最大值池化 Max Pooling，一种是平均值池化 Mean/Average Pooling。

#### 简介
池化

- 最大值池化，是取当前池化视野中所有元素的最大值，输出到下一层特征图中。
- 平均值池化，是取当前池化视野中所有元素的平均值，输出到下一层特征图中。

其目的是：

- 扩大视野：就如同先从近处看一张图片，然后离远一些再看同一张图片，有些细节就会被忽略
- 降维：在保留图片局部特征的前提下，使得图片更小，更易于计算
- 平移不变性，轻微扰动不会影响输出：比如上图中最大值池化的4，即使向右偏一个像素，其输出值仍为4
- 维持同尺寸图片，便于后端处理：假设输入的图片不是一样大小的，就需要用池化来转换成同尺寸图片

一般我们都使用最大值池化。

#### 池化层的训练

- 对于最大值池化，残差值会回传到当初最大值的位置上，而其它三个位置的残差都是0。
- 对于平均值池化，残差值会平均到原始的4个位置上。

#### 性能测试
结果：
![avatar](\picture\ch17-5.png)

## 卷积神经网络应用

### 经典卷积神经网络模型

#### LeNet (1998)
卷积神经网络的鼻祖LeNet的模型结构。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/18/Net_LeNet.png" />

#### AlexNet (2012)
AlexNet网络结构在整体上类似于LeNet，都是先卷积然后在全连接。但在细节上有很大不同。AlexNet更为复杂。AlexNet有60 million个参数和65000个神经元，五层卷积，三层全连接网络，最终的输出层是1000通道的Softmax。

AlexNet的模型结构。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/18/Net_AlexNet.png" />

特点：
- 比LeNet深和宽的网络
- 数据增强
- 使用ReLU做激活函数
- 在全连接层使用DropOut
- 使用LRN

#### ZFNet (2013)
ZFNet是2013年ImageNet分类任务的冠军，其网络结构没什么改进，只是调了调参，性能较Alex提升了不少。

#### VGGNet (2015)
VGG Net由牛津大学的视觉几何组（Visual Geometry Group）和 Google DeepMind公司的研究员一起研发的的深度卷积神经网络，它主要的贡献是展示出网络的深度（depth）是算法优良性能的关键部分。

VGG16（16层的VGG）模型结构。

<img src="https://aiedugithub4a2.blob.core.windows.net/a2-images/Images/18/Net_Vgg16.png" ch="500" />

#### GoogLeNet (2014)
GoogLeNet在2014的ImageNet分类任务上击败了VGG-Nets,在加深网络的同时（22层），也在网络结构上做了创新，引入Inception结构代替了单纯的卷积+激活的传统操作。

#### ResNets (2015)
ResNet在网络结构上做了大创新，而不再是简单的堆积层数，ResNet在卷积神经网络的新思路，绝对是深度学习发展历程上里程碑式的事件。

#### DenseNet (2017)
DenseNet是一种具有密集连接的卷积神经网络。在该网络中，任何两层之间都有直接的连接.

优点：
1. 相比ResNet拥有更少的参数数量
2. 旁路加强了特征的重用
3. 网络更易于训练,并具有一定的正则效果
4. 缓解了gradient vanishing和model degradation的问题

### 颜色分类

由于输入图片是三通道的彩色图片，我们先把它转换成灰度图。

在转换成灰度图后，立刻用reshape(1,784)把它转变成矢量，该矢量就是每个样本的784维的特征值。

#### 实现
结果：
![avatar](\picture\ch18-1.1.png)
![avatar](\picture\ch18-1.3.png)
![avatar](\picture\ch18-1.4.png)

### 图形分类

#### 实现
结果：
![avatar](\picture\ch18-2.2.png)

#### 可视化
![avatar](\picture\ch18-2.1.png)

### 图形及颜色
结果：
![avatar](\picture\ch18-3.png)

### MNIST分类问题
在做池化时，应该尽量让输入的矩阵尺寸是偶数，如果不是的话，应该在上一层卷积层加padding，使得卷积的输出结果矩阵的宽和高为偶数。

每一次重新训练后，特征可能会变成其它几种组合，顺序也会发生改变，这取决于初始化数值及样本顺序、批大小等等因素。

#### 实现
结果：
![avatar](\picture\ch18-4.png)

### Fashion-MNIST分类
复杂版的MNIST分类问题，增加了图片的复杂度。

### Cifar-10分类
Cifar-10 是由 Hinton 的学生 Alex Krizhevsky、Ilya Sutskever 收集的一个用于普适物体识别的数据集。

#### 实现
结果：
![avatar](\picture\ch18-5.png)